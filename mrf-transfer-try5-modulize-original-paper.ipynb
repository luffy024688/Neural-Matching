{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is enabled with initial size: 75.0% of memory, CuDNN 4007)\n",
      "/usr/lib/python3.4/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Theano/Lasagne\n",
    "import theano\n",
    "import lasagne\n",
    "import theano.tensor as T\n",
    "from lasagne.utils import floatX\n",
    "from lasagne.layers import *\n",
    "\n",
    "# numpy/scipy/scikit\n",
    "import numpy as np\n",
    "import skimage.transform\n",
    "import scipy.optimize\n",
    "\n",
    "# notebook\n",
    "from nbtools import display_img_array\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# for vgg19 model and conv2dlayer\n",
    "from vgg_model import load_vgg19, ConvLayer\n",
    "\n",
    "# neural style helper functions\n",
    "from ns_helpers import prep_image, imread, get_img, Func, Eval, Shared, deprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load vgg19 model and set feature layer for neural matching\n",
    "net = load_vgg19(pkl_filename='vgg19.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use conv to find nearest neighbor of a patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# builder of best_match\n",
    "# not using lru_cache because of python 2.7 compatibility\n",
    "def build_best_match(C, psize, num_patches, input_img, mem={}):\n",
    "    key = (C, psize, num_patches)\n",
    "    if key not in mem:\n",
    "        # compute norm\n",
    "        #input_img = T.tensor4()\n",
    "        layer_img = InputLayer((1, C, None, None), input_var=input_img)\n",
    "        layer_sqr_sum = ExpressionLayer(layer_img,  lambda x:T.sum(T.sqr(x), axis=1,keepdims=True) , output_shape=(1,1,None,None))\n",
    "        layer_norm = ConvLayer(layer_sqr_sum, 1, psize, pad='valid', W=floatX(np.ones((1, 1, psize,psize))), b=None, nonlinearity=T.sqrt)\n",
    "        layer_norm_reshape = ReshapeLayer(layer_norm, ([2], [3]))\n",
    "        # compute correlation\n",
    "        input_patch = T.tensor4()\n",
    "        patch_sqr_sum = (input_patch**2).sum(axis=3).sum(axis=2).sum(axis=1).reshape((1, num_patches, 1, 1))\n",
    "        layer_prod= ConvLayer(layer_img, num_patches, psize, pad='valid', W=input_patch, b=None, nonlinearity=None)\n",
    "        layer_corr = ElemwiseMergeLayer([layer_prod, layer_norm_reshape], lambda a,b: (a/b)/patch_sqr_sum)\n",
    "        layer_corr_output = lasagne.layers.get_output(layer_corr)\n",
    "        # Pack into a function to find the Nearest Neighbor        \n",
    "        mem[key] = theano.function([input_patch], T.max_and_argmax(layer_corr_output, axis=(2,3))+[T.shape(layer_corr_output)])\n",
    "    return mem[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan through the content image, for each PSIZExPSIZE patch in the content image, and find the best match(nearest neighbor) in style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def match_all(photo_feature, style_feature, IMAGE_H, IMAGE_W, PSIZE=3, stride=2):\n",
    "    # there are H rows of patches and W patches at each row.    \n",
    "    assert photo_feature.shape[0] == 1\n",
    "    assert style_feature.shape[0] == 1\n",
    "    assert photo_feature.shape[1]== style_feature.shape[1]\n",
    "    H = photo_feature.shape[2] - PSIZE+1\n",
    "    \n",
    "    W = photo_feature.shape[3] - PSIZE + 1    \n",
    "    # num_patches = 1+ (W-1)//stride\n",
    "    C = photo_feature.shape[1]\n",
    "\n",
    "    # build the best_match routine\n",
    "    input_img = Shared((\"match_input_img\"), style_feature)\n",
    "    best_match = build_best_match(C, PSIZE, W, input_img)\n",
    "\n",
    "    # set up arrays for input patches and output results\n",
    "    patches = np.zeros( shape=(W, photo_feature.shape[1], PSIZE, PSIZE) ,  dtype= photo_feature.dtype)\n",
    "    mapping_idx = np.zeros((H,W), dtype='int64')\n",
    "    mapping_weight = None #np.zeros((H,W), dtype='float32')\n",
    "\n",
    "    # doing the match row by row\n",
    "    for j in range(0, H, stride):\n",
    "        for n in range(W):            \n",
    "                patches[n] = photo_feature[0, :, j:j+PSIZE,n:n+PSIZE ]  \n",
    "        m, idx, s = best_match(patches)\n",
    "        mapping_idx[j] =idx\n",
    "        #mapping_weight[j] = (m+1)**2  # making the weight positive in a some what arbitrary way    \n",
    "    return mapping_idx, mapping_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-ec8b03fadaa8>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-ec8b03fadaa8>\"\u001b[1;36m, line \u001b[1;32m22\u001b[0m\n\u001b[1;33m    return preview, None a2\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def plot_match_result_with_a2(mapping_idx, mapping_weight, src, psize, method):\n",
    "    # assert mapping_idx.shape == mapping_weight.shape\n",
    "    assert method in ('max', 'average')\n",
    "    H, W = mapping_idx.shape\n",
    "    S = src.shape[2]//(H+psize-1)\n",
    "    assert 1 == S\n",
    "    preview = np.zeros(src.shape)\n",
    "    a2 = np.zeros(src.shape)\n",
    "    preview_weight = np.zeros(src.shape)\n",
    "    for j in range(H):\n",
    "        for n in range(W):\n",
    "            y,x = np.unravel_index(mapping_idx[j,n], mapping_idx.shape)\n",
    "            _preview = preview[:,:,j:(j+psize), n:(n+psize)]\n",
    "            _preview_weight = preview_weight[:,:,j:(j+psize), n:(n+psize)]  \n",
    "            _a2 = a2[:,:,j:(j+psize), n:(n+psize)]             \n",
    "            _preview[...] += src[:,:,y:(y+psize), x:(x+psize)]\n",
    "            _preview_weight[...] += 1\n",
    "            _a2 += src[:,:,y:(y+psize), x:(x+psize)]**2\n",
    "    if method == 'average':\n",
    "        preview /= preview_weight\n",
    "        a2 /= preview_weight\n",
    "    return preview, a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set and load content image and style image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img0 = imread(\"CNNMRF/data/content/0.jpg\")\n",
    "img1 = imread(\"CNNMRF/data/style//0.jpg\")\n",
    "imgh, imgw = img0.shape[:2]\n",
    "imgh,imgw = 384, 384*imgw//imgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_img_array(np.hstack([prep_image(img0, imgw, imgh)[0], prep_image(img1, imgw, imgh)[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Style transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set content layers and style layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content_layers = ['conv4_2']\n",
    "#style_layers = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1']\n",
    "mrf_layers = ['conv4_1', 'conv3_1']\n",
    "layers = {k: net[k] for k in content_layers+mrf_layers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basic norm and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    x = x.flatten(ndim=3)\n",
    "    g = T.tensordot(x, x, axes=([2], [2]))\n",
    "    return g\n",
    "\n",
    "def content_loss(P, X, layer):\n",
    "    p = P[layer]\n",
    "    x = X[layer]\n",
    "    loss = 1./(x.shape[0] * x.shape[1]*x.shape[2]*x.shape[3])  * lasagne.objectives.squared_error(x, p).sum()\n",
    "    return loss  \n",
    "\n",
    "def total_variation_loss(x):\n",
    "    return ((((x[:,:,:-1,:-1] - x[:,:,1:,:-1])**2 + (x[:,:,:-1,:-1] - x[:,:,:-1,1:])**2)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrf_loss(A, A2, X, layer):    \n",
    "    a = A[layer]\n",
    "    a2 = A2[layer]\n",
    "    x = X[layer]    \n",
    "    loss = (0.5*(x**2).sum()+a2-(x*a).sum())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer(img0, img1, IMAGE_H, IMAGE_W, PSIZE, init_img=None, mrf_weight=1e-4, content_weight=2e1, tv_weight=1e-3):\n",
    "    # prepare content and style\n",
    "    raw_content, content = prep_image(get_img(img0), IMAGE_W, IMAGE_H)\n",
    "    print(\"content\", content.shape)\n",
    "    raw_style, style = prep_image(get_img(img1), IMAGE_W, IMAGE_H)\n",
    "\n",
    "    input_image = Shared((\"input_image\"), style)\n",
    "    outputs = dict(zip(layers.keys(), lasagne.layers.get_output(layers.values(), input_image))  )  \n",
    "    compute_mrf_features = lambda :{k: np.array(Eval(k, outputs[k])) for k in mrf_layers}\n",
    "    \n",
    "    input_image.set_value(style)\n",
    "    style_mrf_features = compute_mrf_features()\n",
    "    style_features = {k: Shared((\"style_\"+k), v) for k,v in style_mrf_features.items()}\n",
    "    \n",
    "    input_image.set_value(content)\n",
    "    # content_mrf_features = compute_mrf_features()\n",
    "    content_features = {k: Shared((\"content_\"+k), Eval(k, outputs[k])) for k in content_layers}\n",
    "    \n",
    "    # prepare gen_features    \n",
    "    generated_image = input_image\n",
    "    if init_img is not None:\n",
    "        raw_init, init = prep_image(init_img, IMAGE_W, IMAGE_H)\n",
    "        generated_image.set_value(init)        \n",
    "    else:\n",
    "        generated_image.set_value(content)    \n",
    "    gen_features = outputs\n",
    "    \n",
    "    x0 = input_image.get_value()\n",
    "    dx0 = deprocess(x0)            \n",
    "    display_img_array(dx0)\n",
    "    \n",
    "    # prepare inital mapping\n",
    "    \n",
    "    style_a = {}\n",
    "    style_a2 = {}\n",
    "    \n",
    "    def update_mrf_loss_weight():\n",
    "        x0_mrf_features = compute_mrf_features()        \n",
    "        for k in mrf_layers:\n",
    "            src = style_mrf_features[k]\n",
    "            mapping_idx, mapping_weight = match_all(x0_mrf_features[k], src, IMAGE_H, IMAGE_W, PSIZE)\n",
    "            A, A2 = plot_match_result_with_a2(mapping_idx, mapping_weight, src, PSIZE, \"average\")\n",
    "            style_a[k] = Shared(('A_'+k), floatX(A))            \n",
    "            style_a2[k] = Shared(('A2_'+k), floatX(A2.sum())) \n",
    "            \n",
    "    update_mrf_loss_weight()\n",
    "    tv_scalar = Shared('tv_weight', tv_weight)\n",
    "    c_scalar = Shared(\"content_weight\", content_weight)\n",
    "    s_scalar = Shared(\"mrf_weight\", mrf_weight)\n",
    "    tv_loss = tv_scalar * total_variation_loss(generated_image) \n",
    "    c_loss = 0.\n",
    "    for layer in content_layers:\n",
    "           c_loss += c_scalar * content_loss(content_features, gen_features, layer)\n",
    "    s_loss = 0.\n",
    "    for layer in mrf_layers:\n",
    "            s_loss +=  s_scalar * mrf_loss(style_a, style_a2,  gen_features, layer)\n",
    "            \n",
    "    total_loss = tv_loss + c_loss+ s_loss\n",
    "    f_errors = Func(('errors'), [], [tv_loss, c_loss, s_loss])\n",
    "    grad = T.grad(total_loss, generated_image)\n",
    "    # Theano functions to evaluate loss and gradient\n",
    "    f_loss = Func((\"loss\"), [], total_loss)        \n",
    "    f_grad = Func((\"grad\"), [], grad)        \n",
    "    x0 = generated_image.get_value().astype('float64')\n",
    "    \n",
    "    def eval_loss(x0):        \n",
    "        x0 = floatX(x0.reshape((1, 3, IMAGE_H, IMAGE_W)))\n",
    "        generated_image.set_value(x0)\n",
    "        update_mrf_loss_weight()\n",
    "        return f_loss().astype('float64')\n",
    "\n",
    "    def eval_grad(x0):        \n",
    "        return np.array(f_grad()).flatten().astype('float64')\n",
    "    \n",
    "    for i in range(10):\n",
    "        x, loss, d = scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxiter= 40, factr=1e1)    \n",
    "        x0 = generated_image.get_value()\n",
    "        errors = [float(x) for x in f_errors()]        \n",
    "        print(i, loss, errors, d)\n",
    "        dx0 = deprocess(x0)\n",
    "        display_img_array(dx0)\n",
    "        if d['warnflag']==0:\n",
    "            break\n",
    "    return dx0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dx = transfer(img0, img1, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img0, img1, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img0, img1, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dx = transfer(img1, img0, imgh//4, imgw//4, 3, content_weight=0.5e1)\n",
    "dx = transfer(img1, img0, imgh//2, imgw//2, 3, init_img=dx, content_weight=0.5e1)\n",
    "dx = transfer(img1, img0, imgh, imgw, 3, init_img=dx, content_weight=0.5e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"img/tjw1.jpg\")\n",
    "img3 = imread(\"simpsguestmain.jpg\")\n",
    "imgh, imgw = 480,640\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"img/tjw1.jpg\")\n",
    "img3 = imread(\"Sofia-Vergara-in-the-Simpsons-647x395.jpg\")\n",
    "imgh, imgw = 480,640\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"2015122760189693.jpg\")\n",
    "img3 = imread(\"Sofia-Vergara-in-the-Simpsons-647x395.jpg\")\n",
    "imgh, imgw = 480,640\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"img/tjw1.jpg\")\n",
    "img3 = imread(\"CNNMRF/data/style/picasso.jpg\")\n",
    "imgh, imgw = img3.shape[:2]\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"CNNMRF/data/content/potrait1.jpg\")\n",
    "img3 = imread(\"CNNMRF/data/style/picasso.jpg\")\n",
    "imgh, imgw = img3.shape[:2]\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"CNNMRF/data/content/potrait1.jpg\")\n",
    "img2 = imread(\"img/tjw1.jpg\")\n",
    "img3 = imread(\"img/Paris-Musee-DOrsay-Vincent-van-Gogh-1889-Self-Portrait-2-Close-Up.jpg\")\n",
    "imgh, imgw = 384,420\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = imread(\"CNNMRF/data/content/d.jpg\")\n",
    "img3 = imread(\"CNNMRF/data/style/d.jpg\")\n",
    "imgh, imgw = img2.shape[:2]\n",
    "dx = transfer(img2, img3, imgh//4, imgw//4, 3)\n",
    "dx = transfer(img2, img3, imgh//2, imgw//2, 3, init_img=dx)\n",
    "dx = transfer(img2, img3, imgh, imgw, 3, init_img=dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_img_array(img1, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_img_array(dx, width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
